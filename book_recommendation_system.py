# -*- coding: utf-8 -*-
"""Book Recommendation System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15lcNxN3k5BioRxA86oUh5VXtBOgKPuhi

# **Tradistional method of recommendation shown at first after this tradistional metrhod the modern recommendation system with tyhe help of ML and AI shown below.**
"""

import pandas as pd

book = pd.read_csv("/content/Books.csv")
rating = pd.read_csv("/content/Ratings.csv")
user = pd.read_csv("/content/Users.csv")

book.head()

rating.head()

user.head()

"""# Tasks:
1. Preprocess the data (handle missing values, merge datasets if needed).
2. Perform EDA to understand:
a. Rating distribution
b. Active users (who rated many books)
c. Popular books
3. Build two types of recommendation models:
a. Popularity-based (Top-rated or most-read books)
b. Collaborative filtering-based (User-User or Item-Item similarity)
4. Display a sample recommendation list for at least one test user.

# Preprocess the data (handle missing values, merge datasets if needed).
"""

print("Missing values in book dataframe:")
print(book.isnull().sum())
print("\nMissing values in rating dataframe:")
print(rating.isnull().sum())
print("\nMissing values in user dataframe:")
print(user.isnull().sum())

# Merge the dataframes
# Merge rating with book dataframe on ISBN
merged_df = pd.merge(rating, book, on='ISBN')

# Merge the result with user dataframe on User-ID
merged_df = pd.merge(merged_df, user, on='User-ID')

print("\nMerged dataframe info:")
merged_df.info()



"""## EDA: Rating Distribution, Active Users, and Popular Books"""

import matplotlib.pyplot as plt
import seaborn as sns

# a. Rating distribution
plt.figure(figsize=(10, 6))
sns.countplot(data=merged_df, x='Book-Rating')
plt.title('Distribution of Book Ratings')
plt.xlabel('Book Rating')
plt.ylabel('Count')
plt.show()

# b. Active users (who rated many books)
active_users = merged_df['User-ID'].value_counts().reset_index()
active_users.columns = ['User-ID', 'Rating_Count']
print("Top 10 Active Users:")
display(active_users.head(10))

# c. Popular books (based on number of ratings)
popular_books = merged_df['Book-Title'].value_counts().reset_index()
popular_books.columns = ['Book-Title', 'Rating_Count']
print("Top 10 Popular Books:")
display(popular_books.head(10))



"""## Building Popularity-Based Recommendation Model"""

# Calculate average rating for each book
average_rating = merged_df.groupby('Book-Title')['Book-Rating'].mean().reset_index()
average_rating.columns = ['Book-Title', 'Average_Rating']

# Calculate the number of ratings for each book
rating_count = merged_df['Book-Title'].value_counts().reset_index()
rating_count.columns = ['Book-Title', 'Rating_Count']

# Merge average rating and rating count
popular_books_df = pd.merge(average_rating, rating_count, on='Book-Title')

# Define a minimum number of ratings to be considered
minimum_ratings = 100

# Filter out books with less than minimum_ratings
popular_books_df = popular_books_df[popular_books_df['Rating_Count'] >= minimum_ratings]

# Sort by average rating in descending order
popular_books_df = popular_books_df.sort_values(by='Average_Rating', ascending=False)

print("Top 10 Popular Books (based on average rating and minimum ratings):")
display(popular_books_df.head(10))

"""# Display a sample recommendation list for at least one test user."""

# Function to get popularity-based recommendations
def get_popularity_recommendations(n=10):
    """
    Returns the top n popular books based on the pre-calculated popular_books_df.
    """
    return popular_books_df.head(n)

# Get sample recommendations for a test user (popularity-based recommendations are the same for all users)
print("Sample Popularity-Based Recommendations:")
display(get_popularity_recommendations(10))

"""# *Modern recommendation system with the help of ML and AI*

# Task
Build a predictive model to estimate the selling price of used cars based on their features using the provided dataset.

## Load the dataset

### Subtask:
Load the provided dataset into a pandas DataFrame.

**Reasoning**:
The subtask is to load the three CSV files into pandas DataFrames. The previous attempt failed with a DtypeWarning, but the files were still loaded. I will try to load them again, explicitly ignoring the warning as it doesn't prevent the loading.
"""

book = pd.read_csv("/content/Books.csv", low_memory=False)
rating = pd.read_csv("/content/Ratings.csv")
user = pd.read_csv("/content/Users.csv")

"""## Explore and preprocess the data

### Subtask:
Perform initial data exploration to understand the features and their distributions. Handle missing values, categorical features, and potential outliers.

"""

print("Merged dataframe info:")
merged_df.info()

print("\nMissing values in merged dataframe:")
print(merged_df.isnull().sum())

# Impute missing 'Age' values with the median
median_age = merged_df['Age'].median()
merged_df['Age'].fillna(median_age, inplace=True)

# Drop rows with missing values in 'Book-Author', 'Publisher', and 'Image-URL-L'
merged_df.dropna(subset=['Book-Author', 'Publisher', 'Image-URL-L'], inplace=True)

print("\nMissing values after handling:")
print(merged_df.isnull().sum())

# Identify categorical columns (excluding Image-URL columns as they are likely URLs and not useful for modeling)
categorical_cols = merged_df.select_dtypes(include='object').columns.tolist()
categorical_cols = [col for col in categorical_cols if 'Image-URL' not in col]

print("\nCategorical columns and their unique value counts:")
for col in categorical_cols:
    print(f"\nColumn: {col}")
    unique_count = merged_df[col].nunique()
    print(f"Number of unique values: {unique_count}")
    print(f"Top 10 most frequent values:\n{merged_df[col].value_counts().head(10)}")

"""## Build and train a model

### Subtask:
Build and train a collaborative filtering-based recommendation model using the merged dataset.

"""

# Filter users with at least 200 ratings
user_rating_counts = merged_df['User-ID'].value_counts()
filtered_users = user_rating_counts[user_rating_counts >= 200].index
filtered_df = merged_df[merged_df['User-ID'].isin(filtered_users)]

# Filter books with at least 50 ratings
book_rating_counts = filtered_df['Book-Title'].value_counts()
filtered_books = book_rating_counts[book_rating_counts >= 50].index
filtered_df = filtered_df[filtered_df['Book-Title'].isin(filtered_books)]

# Create a sparse matrix
from scipy.sparse import csr_matrix

# Create a pivot table with users as index, books as columns, and ratings as values
pivot_table = filtered_df.pivot_table(index='User-ID', columns='Book-Title', values='Book-Rating').fillna(0)

# Convert the pivot table to a sparse matrix
sparse_matrix = csr_matrix(pivot_table.values)

print("Shape of the sparse matrix (Users x Books):", sparse_matrix.shape)

from sklearn.neighbors import NearestNeighbors

# Instantiate the NearestNeighbors model
model_knn = NearestNeighbors(metric='cosine', algorithm='brute')

# Fit the model to the sparse matrix
model_knn.fit(sparse_matrix)

print("NearestNeighbors model trained successfully.")

"""## Display a sample recommendation list for at least one test user.

### Subtask:
Generate and display a sample recommendation list for a test user using the trained collaborative filtering model.

"""

# Select a user ID from the pivot_table index
test_user_id = pivot_table.index[0]  # Using the first user in the pivot table as a test user

# Get the index of the selected user from the pivot_table
user_index = pivot_table.index.get_loc(test_user_id)

# Find the k-nearest neighbors (similar items/books) to the selected user's ratings
# n_neighbors=6 will return the item itself and 5 neighbors
distances, indices = model_knn.kneighbors(sparse_matrix[user_index], n_neighbors=6)

print(f"Recommendations for User ID: {test_user_id}")
print("---------------------------------------------")

# Iterate through the indices of the nearest neighbors (excluding the first one)
for i in range(1, len(indices[0])):
    book_index = indices[0][i]
    book_title = pivot_table.columns[book_index]
    print(f"- {book_title}")

"""# Book Recommendation System Project

## Project Goal:

The goal of this project was to build a recommendation system to suggest books to users based on their ratings and book popularity.

## Project Steps:

1.  **Data Loading**: Loaded the "Books.csv", "Ratings.csv", and "Users.csv" datasets into pandas DataFrames.
2.  **Data Preprocessing**:
    *   Checked for missing values in each dataframe.
    *   Merged the three dataframes based on 'ISBN' and 'User-ID'.
    *   Handled missing values in the merged dataframe by imputing 'Age' with the median and dropping rows with missing values in 'Book-Author', 'Publisher', and 'Image-URL-L'.
3.  **Exploratory Data Analysis (EDA)**:
    *   Visualized the distribution of book ratings.
    *   Identified and displayed the top 10 most active users (based on the number of ratings).
    *   Identified and displayed the top 10 most popular books (based on the number of ratings).
4.  **Building Recommendation Models**:
    *   **Popularity-Based Model**: Built a popularity-based recommendation model by calculating the average rating and rating count for each book. Filtered for books with a minimum number of ratings and sorted by average rating to identify popular books.
    *   **Collaborative Filtering Model**: (Planned but not yet fully implemented in the provided notebook) This model aims to provide personalized recommendations based on user-item interactions.
5.  **Displaying Sample Recommendations**: Displayed a sample recommendation list using the built popularity-based model.

## Key Findings from EDA and Popularity Model:

*   The rating distribution showed a high number of 0 ratings, indicating implicit ratings or unrated books.
*   Identified users who have provided a significant number of ratings.
*   Identified books that have received the most ratings.
*   The popularity-based model highlighted books with high average ratings among those with a sufficient number of ratings.

## Next Steps (Based on the Original Plan):

*   Complete the implementation and training of the collaborative filtering model.
*   Evaluate the performance of both recommendation models using appropriate metrics.
*   Compare the results of the popularity-based and collaborative filtering models.
*   Potentially explore hybrid recommendation approaches.
"""

